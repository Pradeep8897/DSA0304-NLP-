import nltk
from nltk import pos_tag,word_tokenize
nltk.download('punkt',quiet=True)
nltk.download('averaged_perceptron_tagger',quiet=True)
text="Dogs bark. She walk to school every day."
tokens=word_tokenize(text)
tags=pos_tag(tokens)
def transform(tags):
    out=[]
    for i,(w,t) in enumerate(tags):
        if t=='VB' and i>0 and tags[i-1][1] in ('PRP','NN','NNS'):
            if tags[i-1][0].lower() in ('he','she','it') or tags[i-1][1]=='NNS':
                out.append((w,'VBZ'))
                continue
        if t=='NN' and w.endswith('s'):
            out.append((w,'NNS'))
            continue
        out.append((w,t))
    return out
print(transform(tags))


output:
[('Dogs', 'NNS'), ('bark', 'NN'), ('.', '.'), ('She', 'PRP'), ('walk', 'VBD'), ('to', 'TO'), ('school', 'NN'), ('every', 'DT'), ('day', 'NN'), ('.', '.')]
